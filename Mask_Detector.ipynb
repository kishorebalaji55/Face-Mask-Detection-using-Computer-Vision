{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6onRKHXlPrP"
   },
   "source": [
    "# Mask Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DKqNc8DX_w"
   },
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2vVe92rlFAoE"
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mucg4r46nJKq"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zJnCdcuw9s"
   },
   "source": [
    "# Organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2MZwvvLftXBm"
   },
   "outputs": [],
   "source": [
    "# define path and catogories for classification\n",
    "path_dir = \"D:/github/Mask Detection/mask_detector-master/data\"\n",
    "categories = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_e6jNr6DxXR"
   },
   "source": [
    "## Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9-QRvUwuooS",
    "outputId": "9ad1bfe0-bff5-4a8d-888d-a173b7877cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the images\n",
      "All images loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the images\")\n",
    "# make arrays for storing dataset of images and it's label of \n",
    "# with mask and wihtout mask\n",
    "dataset = []\n",
    "label = []\n",
    "# join path for preprocessing of images\n",
    "for category in categories:\n",
    "    path = os.path.join(path_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        #print (img_path)\n",
    "        Img = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "        Img = keras.preprocessing.image.img_to_array(Img)\n",
    "        Img = keras.applications.mobilenet_v2.preprocess_input(Img)\n",
    "\n",
    "        dataset.append(Img)\n",
    "        label.append(category)\n",
    "\n",
    "print(\"All images loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPXuBbJHD-YI"
   },
   "source": [
    "## Convert categories into binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t_43ZoomFPvB"
   },
   "outputs": [],
   "source": [
    "# Convert two categories into binary format like 0,1\n",
    "label_binarizer = LabelBinarizer()\n",
    "# Transform multi-class labels to binary labels\n",
    "label = label_binarizer.fit_transform(label)\n",
    "# Converts a class vector (integers) to binary class matrix\n",
    "label = keras.utils.to_categorical(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz6ClQ4_EJy3"
   },
   "source": [
    "## Create arrays of dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IV9hRP5k5f8t"
   },
   "outputs": [],
   "source": [
    "dataset = np.array(dataset, dtype=\"float32\")\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzulvic5u8yd"
   },
   "source": [
    "## Split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-GnHgJtC780k"
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(dataset, label,\n",
    "\ttest_size=0.20, stratify=label, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFlXnoAuEdoK"
   },
   "source": [
    "## Apply augmentation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XLnnAbQn8DsQ"
   },
   "outputs": [],
   "source": [
    "#use augmentation to increase variation in dataset by various operation like shifting and rotating images\n",
    "data_augmentation = keras.preprocessing.image.ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.07,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.10, \n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB_xHP1RGI7G"
   },
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPHpgRxcEok6"
   },
   "source": [
    "## Load pretrained mobilenetv2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuwq7VxGcaYe",
    "outputId": "2942bb97-cc32-4eda-bed2-d91f7b86f2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# input_shape is shape of image(height, width, channeli.e. 3 here RGB)\n",
    "# include_top is for fully connected layer\n",
    "# imagenet is weights from pre-trained model\n",
    "pre_trained_model = keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=keras.layers.Input(shape=(224, 224, 3)))\n",
    "\n",
    "# we will freeze the base model to prevent them from updation while training\n",
    "for layer in pre_trained_model.layers:\n",
    "\tlayer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJKV5xFJE3Hn"
   },
   "source": [
    "## Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NHLbUx8iBL8D"
   },
   "outputs": [],
   "source": [
    "model = tensorflow.keras.Sequential(\n",
    "    [keras.Input(shape=(224, 224, 3)),\n",
    "     pre_trained_model,\n",
    "     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "     keras.layers.Dense(720, activation=\"relu\"),\n",
    "     keras.layers.Dense(32, activation=\"relu\"),\n",
    "     keras.layers.Dropout(0.3),\n",
    "     keras.layers.Flatten(),\n",
    "     keras.layers.Dense(units=2,activation=\"softmax\")\n",
    "     ] \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYlNJpvFFCtL"
   },
   "source": [
    "# Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tydL3_l7FjY",
    "outputId": "d61d5f01-ae77-447b-fd2f-5dd66f29e013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 1280)        0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3, 3, 720)         922320    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3, 3, 32)          23072     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 578       \n",
      "=================================================================\n",
      "Total params: 3,203,954\n",
      "Trainable params: 945,970\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build([None, 224, 224, 3])\n",
    "#print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gujnxSaqFHxg"
   },
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w943x0s08Wpv"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duzmyFpjFM_z"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VzLdUzk8d7s",
    "outputId": "fba0231b-3b02-4d28-c3fe-066a1c9b27b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "68/68 [==============================] - 90s 1s/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 0.0670 - val_accuracy: 0.9789\n",
      "Epoch 2/30\n",
      "68/68 [==============================] - 86s 1s/step - loss: 0.0480 - accuracy: 0.9923 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
      "Epoch 3/30\n",
      "68/68 [==============================] - 84s 1s/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0433 - val_accuracy: 0.9860\n",
      "Epoch 4/30\n",
      "68/68 [==============================] - 90s 1s/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.0407 - val_accuracy: 0.9930\n",
      "Epoch 5/30\n",
      "68/68 [==============================] - 89s 1s/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.0386 - val_accuracy: 0.9906\n",
      "Epoch 6/30\n",
      "68/68 [==============================] - 91s 1s/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.1459 - val_accuracy: 0.9626\n",
      "Epoch 7/30\n",
      "68/68 [==============================] - 95s 1s/step - loss: 0.0434 - accuracy: 0.9911 - val_loss: 0.1057 - val_accuracy: 0.9708\n",
      "Epoch 8/30\n",
      "68/68 [==============================] - 95s 1s/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0280 - val_accuracy: 0.9930\n",
      "Epoch 9/30\n",
      "68/68 [==============================] - 98s 1s/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.0389 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "68/68 [==============================] - 97s 1s/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.1025 - val_accuracy: 0.9743\n",
      "Epoch 11/30\n",
      "68/68 [==============================] - 97s 1s/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0420 - val_accuracy: 0.9930\n",
      "Epoch 12/30\n",
      "68/68 [==============================] - 98s 1s/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0529 - val_accuracy: 0.9860\n",
      "Epoch 13/30\n",
      "68/68 [==============================] - 97s 1s/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.0355 - val_accuracy: 0.9918\n",
      "Epoch 14/30\n",
      "68/68 [==============================] - 97s 1s/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.1022 - val_accuracy: 0.9696\n",
      "Epoch 15/30\n",
      "68/68 [==============================] - 98s 1s/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0371 - val_accuracy: 0.9930\n",
      "Epoch 16/30\n",
      "68/68 [==============================] - 97s 1s/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
      "Epoch 17/30\n",
      "68/68 [==============================] - 96s 1s/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0424 - val_accuracy: 0.9930\n",
      "Epoch 18/30\n",
      "68/68 [==============================] - 89s 1s/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0430 - val_accuracy: 0.9848\n",
      "Epoch 19/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0629 - val_accuracy: 0.9883\n",
      "Epoch 20/30\n",
      "68/68 [==============================] - 91s 1s/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0503 - val_accuracy: 0.9813\n",
      "Epoch 21/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0256 - val_accuracy: 0.9953\n",
      "Epoch 22/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0865 - val_accuracy: 0.9789\n",
      "Epoch 23/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0179 - accuracy: 0.9922 - val_loss: 0.0535 - val_accuracy: 0.9860\n",
      "Epoch 24/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0343 - val_accuracy: 0.9930\n",
      "Epoch 25/30\n",
      "68/68 [==============================] - 89s 1s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
      "Epoch 26/30\n",
      "68/68 [==============================] - 89s 1s/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0626 - val_accuracy: 0.9719\n",
      "Epoch 27/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0677 - val_accuracy: 0.9942\n",
      "Epoch 28/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0290 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9953\n",
      "Epoch 29/30\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0280 - val_accuracy: 0.9953\n",
      "Epoch 30/30\n",
      "68/68 [==============================] - 91s 1s/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.0310 - val_accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "EPOCHS =30\n",
    "batchSize = 50\n",
    "FIT = model.fit(\n",
    "\tdata_augmentation.flow(trainX, trainY, batch_size=batchSize),\n",
    "\tsteps_per_epoch=len(trainX) // batchSize,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // batchSize,\n",
    "\tepochs= EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeBR0yvdFXiB"
   },
   "source": [
    "## Prediction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TNcfi-r18sbz"
   },
   "outputs": [],
   "source": [
    "PREDICT = model.predict(testX, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sRDYnptFcs9"
   },
   "source": [
    "## Check test batch accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fkY98dNz8zc-"
   },
   "outputs": [],
   "source": [
    "# Make 2 lists to contain max values for predicted and actual test values\n",
    "pred_class = []\n",
    "ac_class = []\n",
    "for i in range(len(PREDICT)):\n",
    "    pr = PREDICT[i].argmax()\n",
    "    pred_class.append(pr)\n",
    "    ac = testY[i].argmax()\n",
    "    ac_class.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iapxn_U_YO8Q"
   },
   "outputs": [],
   "source": [
    "# Make 2 lists to contain the predicted and actual output results gained from \n",
    "# comparing max values in last step with alotted strings     \n",
    "output = {0:\"with_mask\", 1:\"wihout_mask\"}\n",
    "pred_op = []\n",
    "ac_op = []\n",
    "for i in range(len(pred_class)):\n",
    "   pred_op.append(output[pred_class[i]])\n",
    "   ac_op.append(output[ac_class[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-SVtn5_YTar",
    "outputId": "8636bac8-2e22-4f61-e670-029238c92342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of batch =  98.0 %\n"
     ]
    }
   ],
   "source": [
    "# Increment counter if the actual and predicted values match. Then calculate \n",
    "# % accuracy of the first batch.\n",
    "correct_pred = 0\n",
    "for i in range(batchSize):\n",
    "    if pred_op[i] == ac_op[i]:\n",
    "        correct_pred += 1\n",
    "\n",
    "print(\"Accuracy of batch = \", (correct_pred/batchSize)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvvklOAtFiap"
   },
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UfzZzpous_s",
    "outputId": "4463d7c2-f8ac-43bd-9d18-6ed78378c34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "print(\"The model is saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sequential Mask_Detector ",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "pyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
